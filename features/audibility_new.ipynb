{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b729a0d-23da-452f-9892-41f2af8b69a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import naplib\n",
    "import soundfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6367d810-696b-4e01-b837-0301696f1d03",
   "metadata": {},
   "source": [
    "## Word audibility using the spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "524f18ba-79e0-44e5-8afb-9babb4e0e9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.getLogger(\"naplib\").setLevel(logging.FATAL)\n",
    "\n",
    "\n",
    "\n",
    "targets_complete = pd.read_csv('target_distractor_final_final.csv', sep = \";\")\n",
    "\n",
    "directory = './word_seg_targets_final/'\n",
    "\n",
    "sent_id = []\n",
    "words = []\n",
    "start = []\n",
    "end = []\n",
    "word_order = []\n",
    "\n",
    "##Load the word onsets\n",
    "for root,dirs,files in os.walk(directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            if file[:3] in list(targets_complete['target'].str[:3]):\n",
    "\n",
    "                p = os.path.join(directory, file)\n",
    "                f=pd.read_csv(p, sep = \";\")\n",
    "                \n",
    "                ##Remove silence in the beginning and end\n",
    "                f = f.drop(f.loc[(f.MAU == \"(...)\")].index)\n",
    "                f = f.drop(f.loc[f.TOKEN == -1].index)\n",
    "        \n",
    "                words_sent = list(f['TOKEN'].unique())\n",
    "                wo = 1\n",
    "                \n",
    "                for w in words_sent:\n",
    "                    f_w = f.loc[f['TOKEN'] == w]\n",
    "                    word_start = f_w.iloc[0,0]\n",
    "                    word_end = f_w.iloc[-1,0] + f_w.iloc[-1,1]\n",
    "                    word = f_w.iloc[0,5]\n",
    "        \n",
    "                    word_order.append(wo)\n",
    "                    wo = wo + 1\n",
    "                    \n",
    "                    sent_id.append(file)\n",
    "                    words.append(word)\n",
    "                    start.append(word_start)\n",
    "                    end.append(word_end)\n",
    "\n",
    "sent_words = pd.DataFrame(zip(sent_id, words, start, end, word_order), columns = ['id', 'word', 'start', 'end', 'word_order'])\n",
    "\n",
    "##Calculate seconds\n",
    "sent_words['start_s'] = sent_words['start']/44100\n",
    "sent_words['end_s'] = sent_words['end']/44100\n",
    "\n",
    "aud_list = []\n",
    "\n",
    "for s_i in sent_words['id'].unique():\n",
    "    if s_i[0:3] in list(targets_complete['target'].str[:3]):\n",
    "        s_df = sent_words[sent_words['id'] == s_i]\n",
    "    \n",
    "        audio_path = \"../behavior_stimuli/targets_final_norm/\"\n",
    "        audio_path_dis = \"../behavior_stimuli/distractors_new_clean/\"\n",
    "        dis_col = targets_complete[targets_complete['target'].str[:3] == s_i[0:3]]\n",
    "    \n",
    "        dis = dis_col.iloc[0,1]\n",
    "        fpath_dis = audio_path_dis + dis\n",
    "        \n",
    "        y_dis,sr = soundfile.read(fpath_dis)\n",
    "    \n",
    "        fpath = audio_path + s_i[:3] + \".wav\"\n",
    "    \n",
    "        y,sr = soundfile.read(fpath)\n",
    "    \n",
    "        y = y*(pow(10,-10/20))\n",
    "        for i,r in s_df.iterrows():\n",
    "            start_dis = int(44100/2) + r['start']\n",
    "            end_dis = int(44100/2) + r['end']\n",
    "            \n",
    "            y_cut_dis = y_dis[start_dis:end_dis]\n",
    "        \n",
    "            y_cut = y[r['start']:r['end']]\n",
    "    \n",
    "            spx = naplib.features.auditory_spectrogram(y_cut, sr)\n",
    "    \n",
    "            spy = naplib.features.auditory_spectrogram(y_cut_dis, sr)\n",
    "    \n",
    "            glimpsed = abs(spx > spy*(pow(10,-4/20)))\n",
    "            ratio = np.count_nonzero(glimpsed)/np.count_nonzero(spx)\n",
    "            aud_list.append(ratio)\n",
    "\n",
    "\n",
    "sent_words['audibility'] = aud_list\n",
    "\n",
    "df_audibility = sent_words.copy()\n",
    "df_audibility['ids'] = df_audibility['id'].str[0:3]\n",
    "\n",
    "df_audibility['filename'] =  df_audibility['id'].str[0:8]\n",
    "\n",
    "df_audibility = df_audibility.drop(['id', 'start', 'end'], axis=1)\n",
    "\n",
    "df_audibility.to_csv('./trf_input/audibility_words_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbb0a708-68b3-4717-a9d2-642a2c5efcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_complete = pd.read_csv('target_distractor_final_final.csv', sep = \";\")\n",
    "\n",
    "directory = './word_seg_targets_final/'\n",
    "\n",
    "\n",
    "sent_id = []\n",
    "words = []\n",
    "phones = []\n",
    "start = []\n",
    "end = []\n",
    "word_order = []\n",
    "wordnum = []\n",
    "syl_nums = []\n",
    "syls = []\n",
    "\n",
    "for root,dirs,files in os.walk(directory):\n",
    "    for file in files:\n",
    "        if file[:3] in list(targets_complete['target'].str[:3]):\n",
    "\n",
    "            p = os.path.join(directory, file)\n",
    "            if p.endswith(\".csv\"):\n",
    "                f=pd.read_csv(p, sep = \";\")\n",
    "            \n",
    "                ##Remove silence in the beginning and end\n",
    "                f = f.drop(f.loc[(f.MAU == \"(...)\")].index)\n",
    "                f = f.drop(f.loc[f.TOKEN == -1].index)\n",
    "                f = f.reset_index(drop=True)\n",
    "                wo = 1\n",
    "        \n",
    "                syl_add = \"\"\n",
    "                syl_num = 1\n",
    "                syl_count = 1\n",
    "                \n",
    "                for i,p in f.iterrows():\n",
    "                    f_w = p\n",
    "                    phone_start = p.iloc[0]\n",
    "                    phone_end = p.iloc[0] + p.iloc[1]\n",
    "                    phone = p.iloc[3]\n",
    "                    word = p.iloc[5]\n",
    "                    numw = int(p.iloc[2])+1\n",
    "        \n",
    "                    word_order.append(wo)\n",
    "                    wo = wo + 1\n",
    "        \n",
    "    \n",
    "        \n",
    "                    \n",
    "                    sent_id.append(file)\n",
    "                    phones.append(phone)\n",
    "                    words.append(word)\n",
    "                    wordnum.append(numw)\n",
    "        \n",
    "                    start.append(phone_start)\n",
    "                    end.append(phone_end)\n",
    "                \n",
    "\n",
    "\n",
    "sent_words = pd.DataFrame(zip(sent_id, words, phones, start, end, word_order, wordnum), columns = ['id', 'words', 'phone', 'start', 'end', 'phone_order', 'wordnum'])\n",
    "\n",
    "##Calculate seconds\n",
    "sent_words['start_s'] = sent_words['start']/44100\n",
    "sent_words['end_s'] = sent_words['end']/44100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08f3a6bd-2444-4ff5-8714-0405d3879a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.getLogger(\"naplib\").setLevel(logging.FATAL)\n",
    "\n",
    "\n",
    "\n",
    "aud_list = []\n",
    "\n",
    "phone_aud_upsampled = []\n",
    "\n",
    "\n",
    "for s_i in sent_words['id'].unique():\n",
    "    if s_i[0:3] in list(targets_complete['target'].str[:3]):\n",
    "\n",
    "        matches = []\n",
    "        aud_trial = []\n",
    "        up = []\n",
    "        \n",
    "        s_df = sent_words[sent_words['id'] == s_i]\n",
    "    \n",
    "        audio_path = \"../behavior_stimuli/targets_final_norm/\"\n",
    "        audio_path_dis = \"../behavior_stimuli/distractors_new_clean/\"\n",
    "        dis_col = targets_complete[targets_complete['target'].str[:3] == s_i[0:3]]\n",
    "    \n",
    "        dis = dis_col.iloc[0,1]\n",
    "        fpath_dis = audio_path_dis + dis\n",
    "        \n",
    "        y_dis,sr = soundfile.read(fpath_dis)\n",
    "    \n",
    "        fpath = audio_path + s_i[:3] + \".wav\"\n",
    "    \n",
    "        y,sr = soundfile.read(fpath)\n",
    "    \n",
    "        y = y*(pow(10,-10/20))\n",
    "    \n",
    "    \n",
    "        for i,r in s_df.iterrows():\n",
    "            start_dis = int(44100/2) + r['start']\n",
    "            end_dis = int(44100/2) + r['end']\n",
    "            \n",
    "            y_cut_dis = y_dis[start_dis:end_dis]\n",
    "        \n",
    "            y_cut = y[r['start']:r['end']]\n",
    "    \n",
    "            spx = naplib.features.auditory_spectrogram(y_cut, sr)\n",
    "    \n",
    "            spy = naplib.features.auditory_spectrogram(y_cut_dis, sr)\n",
    "            \n",
    "            glimpsed = abs(spx > spy*(pow(10,-4/20)))\n",
    "            ratio = np.count_nonzero(glimpsed)/np.count_nonzero(spx)\n",
    "            aud_list.append(ratio)\n",
    "    \n",
    "                            \n",
    "\n",
    "\n",
    "sent_words['audibility'] = aud_list\n",
    "\n",
    "\n",
    "\n",
    "df_audibility_phone = sent_words.copy()\n",
    "\n",
    "df_audibility_phone['ids'] = df_audibility_phone['id'].str[0:3]\n",
    "\n",
    "df_audibility_phone['filename'] =  df_audibility_phone['id'].str[0:8]\n",
    "\n",
    "df_audibility_phone = df_audibility_phone.drop(['id', 'start', 'end'], axis=1)\n",
    "\n",
    "\n",
    "df_audibility_phone.to_csv('./trf_input/audibility_phones_final.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
